# -*- coding: utf-8 -*-
"""
############################### READ SODAR DATA ###############################
Created on Mon Sep 13 21:52:00 2021
@author: N.P.Saraiva

This script reads files generated by Scintec's SODAR with the extension ".mnd".

INSTRUCTIONS:
-> for clean all variables use: %reset -f;
-> check the address of the folder where the data is, in PATH;
-> script works only when all files are set to the same height ranges!

"""

from IPython import get_ipython
get_ipython().magic('reset -sf')    # clear all variables

import datetime as dt
import os
from glob import glob
import pandas as pd
import numpy as np

startTime = dt.datetime.now()       # know the start time

# enter the path of the files here:
PATH = 'D:/natalia_read_data/to_read/data'
os.chdir(PATH)

# create PATH2, which is a previous directory
PATH2, tail = os.path.split(PATH)

# create the folder "result", if it does not exist
if os.path.exists(os.path.join(PATH2, 'results')) == False:
    os.mkdir(os.path.join(PATH2, 'results'))

##############################################################################
# read files (all) ###########################################################
files = sorted(glob('*.mnd'))     # enter with all data in PATH

dfs = [pd.read_csv(f, header=None, sep=';') for f in files]
alldata = pd.concat(dfs,ignore_index=True)
read = alldata[0].astype(str).tolist()

# set the first and the last files
file_i = files[0].split('.')[0]   # fist file
file_l = files[-1].split('.')[0]  # last file

# set all lines who start with ('#PG')
line_number0 = []
for i, info in enumerate(read):
    if info.startswith('#PG'):
        line_number0.append(i)
del i, info

##############################################################################
# remove duplicate data ######################################################
df_ln = pd.DataFrame(line_number0)
alfa = []
for i, info in enumerate (line_number0):
    alfa.append(read[info-1])
df_ln['dado'] = alfa
del alfa, i, info

line_number = []
if df_ln.loc[0,'dado'] == df_ln.loc[1,'dado']:
    line_number.append(df_ln.loc[0,0])
else:
    line_number.append(df_ln.loc[0,0])

cont = 0
while cont < len(line_number0)-1:
    if df_ln.loc[cont,'dado'] != df_ln.loc[cont+1,'dado']:
        line_number.append(df_ln.loc[cont+1,0])
    cont = cont + 1
del cont

##############################################################################
# finding the datetime inicial and final #####################################
d_start = read[line_number[0]-1].split(' ')
d_start = d_start[0]+ ' ' + d_start[1]
d_start = dt.datetime.strptime(d_start, '%Y-%m-%d %H:%M:%S')

d_end = read[line_number[-1]-1].split(' ')
d_end = d_end[0]+ ' ' + d_end[1]
d_end = dt.datetime.strptime(d_end, '%Y-%m-%d %H:%M:%S')

##############################################################################
# read non-profile data (df_1) ###############################################
alfa = []
for i, info in enumerate(line_number):
    bravo = read[info-1],read[info+1]
    alfa.append(bravo)
alfa = list(alfa)
df_1 = pd.DataFrame(alfa)
del alfa, bravo, i, info

# arrange the column with time information to df_1
df_1[['dia', 'hora', 'intervalo']] = df_1[0].str.split(' ', expand=True)
df_1['datetime'] = df_1[['dia', 'hora']].agg(' '.join, axis=1)
df_1['datetime'] = df_1['datetime'].apply(lambda x: dt.datetime.strptime(x,\
    '%Y-%m-%d %H:%M:%S'))
df_1 = df_1.drop(columns=[0, 'dia', 'hora', 'intervalo'])

# arrange the column with data information to df_1
df_1 = df_1.rename(columns={1: 'data'})
header_1 = ['PG', 'h_range', 'h_inv', 'h_mixing', 'H', 'u*', 'L*']
df_1[header_1] = df_1.data.str.split(expand=True)
df_1 = df_1.drop(columns=['data'])

# change type to column date for PeriodIndex
df_1['datetime'] = pd.PeriodIndex(df_1['datetime'], freq = 'S')

# set 'datetime' as an index
df_1 = df_1.set_index(['datetime'])

# filling the missing dates, hours, and minures
idx = pd.DataFrame({'datetime':pd.date_range(start = d_start, end = d_end,\
    freq = '10min')})
idx = pd.PeriodIndex(idx['datetime'], freq = 'S')
df_1 = df_1.reindex(idx, fill_value = np.nan)

# change the type (df_1)
df_1 = df_1.astype('float')

# replace missing data (df_1)
df_1 = df_1.replace({99:np.nan, 99999:np.nan, 9999.9:np.nan, 99.99:np.nan,\
    999999:np.nan}, regex=True)

# save data that is NOT measured by height (df_1)
df_1.to_csv(PATH2 + '/results/%(first)s_to_%(last)s_sodar_non_profile.csv'\
    %{'first':file_i, 'last':file_l}, na_rep = np.nan, index = True)

##############################################################################
# read read profile data (df_2) ##############################################
# find heigths levels intervals
h = list(range(0,(line_number0[1]-2)-(line_number0[0]+3)+1))

charlie = []
for i, info1 in enumerate(line_number):
    for ii, info2 in enumerate(h):
        delta = read[info1-1], read[info1+3+ii]
        charlie.append(delta)
df_2 = pd.DataFrame(charlie)
del charlie, delta, i, info1, ii, info2

# arrange the column with time information to df_2
df_2[['dia', 'hora', 'intervalo']] = df_2[0].str.split(' ',expand=True)
df_2['datetime'] = df_2[['dia', 'hora']].agg(' '.join, axis=1)
df_2['datetime'] = df_2['datetime'].apply(lambda x: dt.datetime.strptime(x,\
    '%Y-%m-%d %H:%M:%S'))
df_2 = df_2.drop(columns=[0, 'dia', 'hora', 'intervalo'])

# arrange the column with data information to df_2
df_2 = df_2.rename(columns={1: 'data'})
header_2 = read[line_number[0]+2].split()
del header_2[0]
df_2[header_2] = df_2.data.str.split(expand=True)
df_2 = df_2.drop(columns=['data'])

# find heigths levels
h_sodar = df_2.z.loc[0:len(h)-1].tolist()
h_sodar = list(map(int, h_sodar))

# change type to column date for PeriodIndex
df_2['datetime'] = pd.PeriodIndex(df_2['datetime'], freq = 'S')

# set 'date' as an index
df_2 = df_2.set_index(['datetime'])

# change the type (df_2)
df_2 = df_2.astype('float')

# replace missing data (df_2)
df_2 = df_2.replace({99999:np.nan, 99.99:np.nan, 999.9:np.nan, 99.999:np.nan,\
    99:np.nan, 99.99999:np.nan, 9.99E+37:np.nan, 999:np.nan}, regex=True)

# filling the missing dates, hours, and minures
    # separate the heights to find the missing lines
cont1 = 0
while cont1 <= len(h_sodar)-1:
    title = 'h_%i' %h_sodar[cont1]
    locals()[title] = df_2.loc[(df_2['z'] == h_sodar[cont1])].\
    reindex(idx, fill_value = np.nan)
    locals()[title]['z'] = locals()[title]['z']\
    .replace(np.nan, h_sodar[cont1])
    cont1 = cont1 + 1
del cont1

    # join all data by height    
df_sodar = pd.DataFrame()

cont2 = 0
while cont2 < len(idx):
    for v, info5 in enumerate(h_sodar):
        bravo = 'h_%i' %info5
        df_sodar = df_sodar.append(locals()[bravo].iloc[cont2])
    cont2 = cont2 + 1
del cont2

# save data that is measured by height (df_2)
df_sodar.to_csv(PATH2 + '/results/%(first)s_to_%(last)s_sodar_profile.csv'\
    %{'first':file_i, 'last':file_l}, na_rep = np.nan, index = True,\
    index_label = 'datetime')

##############################################################################
print('runtime: ', dt.datetime.now() - startTime)
print('Number of file(s):', len(files), '\nSODAR measured at', len(h), 'heights')

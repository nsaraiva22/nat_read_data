# -*- coding: utf-8 -*-
"""
########################## READ SOLYS STATION DATA ###########################
Created on Mon Feb 23 12:54:04 2022
@author: N.P.Saraiva

This script reads the 1-minute files generated by the Campebell datalogger,
which records the data from the solarimetic station, after its conversion into
a "CSV compatible array" with the ".dat" extension.

INSTRUCTIONS:
-> for clean all variables use: %reset -f;
-> check the address of the folder where the data is, in PATH;
"""

from IPython import get_ipython
get_ipython().magic('reset -sf')    # clear all variables

import datetime as dt
import os
from glob import glob
import pandas as pd
import numpy as np

startTime = dt.datetime.now()       # know the start time

# enter the path of the files here:
PATH = 'D:/natalia_read_data/to_read/data'
os.chdir(PATH)

# create PATH2, which is a previous directory
PATH2, tail = os.path.split(PATH)

# create the folder "result", if it does not exist
if os.path.exists(os.path.join(PATH2, 'results')) == False:
    os.mkdir(os.path.join(PATH2, 'results'))

##############################################################################
# read files (all) ###########################################################

files = sorted(glob('*1MIN_P1_*.dat'))     # enter with all data in PATH

# create dataframe 
header = ['BattV', 'PTemp_C', 'WindDir', 'WS_ms_Avg', 'WS_ms_Max', 'WS_ms_Min',\
'AirTC_Avg', 'AirTC_Max', 'AirTC_Min', 'RH_Max', 'RH_Min', 'RH', 'Rain_mm_Tot',\
'BP_mbar_Avg', 'BP_mbar_Max', 'BP_mbar_Min', 'SlrW_CPM10_Horizontal_Avg',\
'SlrW_CPM10_Horizontal_Max', 'SlrW_CPM10_Horizontal_Min',\
'SlrW_CPM10_Horizontal_Tot', 'SlrW_CPM10_Inclinado_Avg',\
'SlrW_CPM10_Inclinado_Max', 'SlrW_CPM10_Inclinado_Min',\
'SlrW_CPM10_Inclinado_Tot', 'SlrW_CHP1_Avg', 'SlrW_CHP1_Max', 'SlrW_CHP1_Min',\
'SlrW_CHP1_Tot', 'SlrW_CMP10_Global_Avg', 'SlrW_CMP10_Global_Max',\
'SlrW_CMP10_Global_Min', 'SlrW_CMP10_Global_Tot', 'SlrW_CMP10_Difusa_Avg',\
'SlrW_CMP10_Difusa_Max', 'SlrW_CMP10_Difusa_Min', 'SlrW_CMP10_Difusa_Tot',\
'SlrW_CGR3_Avg', 'SlrW_CCGR3_Max', 'SlrW_CCGR3_Min', 'SlrW_CCGR3_Tot',\
'BattV_Min', 'SolarAzimut', 'SunElevation', 'HourAngle', 'Declination',\
'AirMass', 'DeclinationDeg', 'HrAngleDeg', 'Local_SolarNoon']

dfs = [pd.read_csv(f, header = None, sep = ',', names =	['x', 'year', 'j_day',\
        'h_min', 'sec'] + header, dtype = str) for f in files]

##############################################################################
# read data (df_solys) #######################################################
df_solys = pd.concat(dfs, ignore_index = True)

# organize date colunm
df_solys['date'] = pd.to_datetime(df_solys['j_day'], format = '%j')
df_solys['date'] = df_solys['date'].dt.strftime('%m-%d')
df_solys['dt1'] = df_solys[['year', 'date']].agg('-'.join, axis=1)

# set the first and the last files
file_i = df_solys.loc[df_solys.index[0], 'dt1'][2:].replace('-','_')   # fist
file_l = df_solys.loc[df_solys.index[-1], 'dt1'][2:].replace('-','_')  # last

# organize hour, minute, and second colunms
df_solys['hour'] = df_solys['h_min'].str[-4:-2]
df_solys['hour'] = df_solys['hour'].apply(lambda x: '{0:0>2}'.format(x))
df_solys['min'] = df_solys['h_min'].str[-2:]
df_solys['dt2'] = df_solys[['hour', 'min', 'sec']].agg(':'.join, axis=1)

# organize datetime colunm
df_solys['datetime'] = df_solys[['dt1', 'dt2']].agg(' '.join, axis=1)
df_solys['datetime'] = pd.to_datetime(df_solys['datetime'],\
format = '%Y-%m-%d %H:%M:%S')
    
df_solys = df_solys.drop(columns=['x', 'year', 'j_day', 'h_min','sec', 'date',\
'dt1', 'hour', 'min', 'dt2'])
    
df_solys = df_solys[['datetime'] + header]

# put a dataframe in ascending order
df_solys = df_solys.sort_values('datetime')

##############################################################################
# for filling the missing rows information ###################################
# finding the datetime inicial and final
d_start = df_solys.loc[df_solys.index[0], 'datetime']
d_end = df_solys.loc[df_solys.index[-1], 'datetime']

# change type to column date for PeriodIndex
df_solys['datetime'] = pd.PeriodIndex(df_solys['datetime'], freq = '1min')

# set 'date' as an index
df_solys = df_solys.set_index(['datetime'])

# filling the missing dates, hours, and minures
idx = pd.DataFrame({'datetime':pd.date_range(start = d_start, end = d_end,\
freq = '1min')})
idx = pd.PeriodIndex(idx['datetime'], freq = '1min')
df_solys = df_solys.reindex(idx, fill_value = np.nan)
del idx, d_start, d_end                 # clean some variables

# change columns types
df_solys = df_solys.astype('float64')

##############################################################################
# saving data (df_solys) #####################################################
df_solys.to_csv(PATH2 + '/results/%(first)s_to_%(last)s_solarimetric_1min.csv'\
    %{'first':file_i, 'last':file_l}, na_rep = np.nan, index = True)

##############################################################################
print('runtime: ', dt.datetime.now() - startTime)
print('Number of file(s):', len(files))
